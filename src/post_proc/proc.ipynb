{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6fb2de4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"/home/handb/GeoSTHN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "95a8a277",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "\n",
    "def _extract_first_float(s):\n",
    "    if not s:\n",
    "        return None\n",
    "    match = re.search(r\"(\\d+\\.\\d+)\", s.strip())\n",
    "    return float(match.group(1)) if match else None\n",
    "\n",
    "\n",
    "def calculate_average_test_mrr(json_file_path, s, e):\n",
    "    \"\"\"\n",
    "    è®¡ç®—JSONç»“æœæ–‡ä»¶ä¸­ test mrr, test auroc, test auprc çš„å¹³å‡å€¼å’Œç»Ÿè®¡ä¿¡æ¯\n",
    "\n",
    "    Args:\n",
    "        json_file_path: JSONç»“æœæ–‡ä»¶è·¯å¾„\n",
    "        s: èµ·å§‹ç´¢å¼•ï¼ˆå¯ä¸ºè´Ÿæ•°æˆ–Noneï¼‰\n",
    "        e: ç»“æŸç´¢å¼•ï¼ˆå¯ä¸ºè´Ÿæ•°æˆ–Noneï¼‰\n",
    "\n",
    "    Returns:\n",
    "        dict: æ¯ä¸ªæŒ‡æ ‡çš„å¹³å‡å€¼ï¼Œå¦‚ {\"test mrr\": avg, \"test auroc\": avg, \"test auprc\": avg}\n",
    "    \"\"\"\n",
    "    with open(json_file_path, \"r\") as f:\n",
    "        results = json.load(f)\n",
    "\n",
    "    metrics = {\"test mrr\": [], \"test auroc\": [], \"test auprc\": []}\n",
    "\n",
    "    for result in results:\n",
    "        for key in metrics.keys():\n",
    "            val = _extract_first_float(result.get(key, \"\"))\n",
    "            if val is not None:\n",
    "                metrics[key].append(val)\n",
    "\n",
    "    # å¦‚æœæ²¡æœ‰ä»»ä½•æ•°æ®\n",
    "    if not any(metrics.values()):\n",
    "        print(\"âŒ æœªæ‰¾åˆ°æœ‰æ•ˆçš„æŒ‡æ ‡æ•°æ®\")\n",
    "        return None\n",
    "\n",
    "    # å¤„ç†åˆ‡ç‰‡å‚æ•°ï¼ˆåŸºäº test mrr çš„é•¿åº¦ä½œä¸ºå‚è€ƒï¼Œå¦‚æœéœ€è¦ä¹Ÿå¯æ”¹ä¸ºæ›´ä¸¥æ ¼çš„æ£€æŸ¥ï¼‰\n",
    "    ref_len = (\n",
    "        len(metrics[\"test mrr\"])\n",
    "        if metrics[\"test mrr\"]\n",
    "        else max(len(v) for v in metrics.values())\n",
    "    )\n",
    "    if s is not None:\n",
    "        if s < 0:\n",
    "            s = max(0, ref_len + s)\n",
    "    else:\n",
    "        s = 0\n",
    "\n",
    "    if e is None:\n",
    "        e = ref_len\n",
    "    elif e < 0:\n",
    "        e = max(0, ref_len + e)\n",
    "\n",
    "    # åˆ‡ç‰‡å¹¶è®¡ç®—ç»Ÿè®¡é‡\n",
    "    sliced = {k: v[s:e] for k, v in metrics.items()}\n",
    "\n",
    "    results_summary = {}\n",
    "    print(\"\\nğŸ“Š ç»Ÿè®¡ç»“æœ:\")\n",
    "    print(f\"è€ƒè™‘èŒƒå›´: [{s}, {e})\")\n",
    "    for k, vals in sliced.items():\n",
    "        if vals:\n",
    "            avg = sum(vals) / len(vals)\n",
    "            std = (sum((x - avg) ** 2 for x in vals) / len(vals)) ** 0.5\n",
    "            mx = max(vals)\n",
    "            mn = min(vals)\n",
    "            print(\n",
    "                f\"{k}: å¹³å‡ {avg:.4f} Â± {std:.4f} (n={len(vals)})ï¼Œmax={mx:.4f}ï¼Œmin={mn:.4f}\"\n",
    "            )\n",
    "            results_summary[k] = avg\n",
    "        else:\n",
    "            print(f\"{k}: âŒ æ— æœ‰æ•ˆæ•°æ®\")\n",
    "            results_summary[k] = None\n",
    "\n",
    "    return results_summary\n",
    "\n",
    "\n",
    "def calculate_stats_by_seed(json_file_path):\n",
    "    \"\"\"\n",
    "    æŒ‰ç…§ seed åˆ†ç»„è®¡ç®— test mrr, test auroc, test auprc çš„ç»Ÿè®¡æ•°æ®\n",
    "    \"\"\"\n",
    "    with open(json_file_path, \"r\") as f:\n",
    "        results = json.load(f)\n",
    "\n",
    "    seed_results = {}  # seed -> {metric: [values]}\n",
    "\n",
    "    for result in results:\n",
    "        seed = result.get(\"seed\", 1)\n",
    "        if seed not in seed_results:\n",
    "            seed_results[seed] = {\"test mrr\": [], \"test auroc\": [], \"test auprc\": []}\n",
    "\n",
    "        for key in seed_results[seed].keys():\n",
    "            val = _extract_first_float(result.get(key, \"\"))\n",
    "            if val is not None:\n",
    "                seed_results[seed][key].append(val)\n",
    "\n",
    "    print(\"\\nğŸ“ˆ æŒ‰Seedåˆ†ç»„ç»Ÿè®¡:\")\n",
    "    overall = {k: [] for k in [\"test mrr\", \"test auroc\", \"test auprc\"]}\n",
    "\n",
    "    for seed, metrics_dict in seed_results.items():\n",
    "        print(f\"\\nSeed {seed}:\")\n",
    "        for k, vals in metrics_dict.items():\n",
    "            if vals:\n",
    "                avg = sum(vals) / len(vals)\n",
    "                std = (sum((x - avg) ** 2 for x in vals) / len(vals)) ** 0.5\n",
    "                print(f\"  {k}: {avg:.4f} Â± {std:.4f} (n={len(vals)})\")\n",
    "                overall[k].extend(vals)\n",
    "            else:\n",
    "                print(f\"  {k}: âŒ æ— æœ‰æ•ˆæ•°æ®\")\n",
    "\n",
    "    print(\"\\nğŸ¯ æ€»ä½“ç»Ÿè®¡:\")\n",
    "    overall_summary = {}\n",
    "    for k, vals in overall.items():\n",
    "        if vals:\n",
    "            avg = sum(vals) / len(vals)\n",
    "            std = (sum((x - avg) ** 2 for x in vals) / len(vals)) ** 0.5\n",
    "            print(f\"  {k}: {avg:.4f} Â± {std:.4f} (n={len(vals)})\")\n",
    "            overall_summary[k] = (avg, std)\n",
    "        else:\n",
    "            print(f\"  {k}: âŒ æ— æœ‰æ•ˆæ•°æ®\")\n",
    "            overall_summary[k] = (None, None)\n",
    "\n",
    "    return overall_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "66c6a7df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ” å¤„ç†æ•°æ®é›†: thgl-forum-subset\n",
      "\n",
      "ğŸ“Š ç»Ÿè®¡ç»“æœ:\n",
      "è€ƒè™‘èŒƒå›´: [0, 10)\n",
      "test mrr: å¹³å‡ 0.8549 Â± 0.0558 (n=10)ï¼Œmax=0.9439ï¼Œmin=0.8047\n",
      "test auroc: å¹³å‡ 0.8275 Â± 0.0867 (n=10)ï¼Œmax=0.9665ï¼Œmin=0.7402\n",
      "test auprc: å¹³å‡ 0.5172 Â± 0.1804 (n=10)ï¼Œmax=0.8460ï¼Œmin=0.3669\n"
     ]
    }
   ],
   "source": [
    "# exper_name = \"hetero_sthn_rgfm\"\n",
    "# exper_name = \"rgfm-htero\"\n",
    "exper_name = \"rgfm-htero-newtrain\"\n",
    "# exper_name = \"abl_no_rie\"\n",
    "# exper_name = \"abl_sthn\"\n",
    "# exper_name = \"abl_no_hetro\"\n",
    "\n",
    "# datasets = [\"thgl-forum-subset\", \"thgl-github-subset\",\"thgl-myket-subset\",\"thgl-software-subset\"]\n",
    "datasets = [\"thgl-forum-subset\"]\n",
    "\n",
    "for dataset in datasets:\n",
    "    json_file_path = f\"exper/{exper_name}/{dataset}/result/{dataset}_results.json\"\n",
    "\n",
    "    print(f\"\\nğŸ” å¤„ç†æ•°æ®é›†: {dataset}\")\n",
    "\n",
    "    # è®¡ç®—å¹³å‡test mrr\n",
    "    calculate_average_test_mrr(json_file_path, s=0, e=None)\n",
    "    # calculate_average_test_mrr(json_file_path,s=None,e=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
